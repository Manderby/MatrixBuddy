<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=768"/>
  <meta name="author" content="Tobias Stamm"/>
  <link rel="stylesheet" type="text/css" href="css.css"/>
  <title>Bit Fiddle</title>
</head>
<body>

<h1>Bit Fiddle</h1>

<article>
<header>
<h2>What does this application do?</h2>
</header>
<ul>
<li>Convert arbitrarily large decimal, hexadecimal or binary numbers or ASCII characters.</li>
<li>Compute the 1's complement or the 2's complement.</li>
<li>Alter the byte order of the input to convert between Little and Big Endian.</li>
<li>View a simple ASCII table with additional information for each character.</li>
</ul>
</article>



<article>
<header>
<h2>User-Interface elements of the main window</h2>
</header>
<p>The main window exists in two forms: An expanded window and a Mini-Version. You can switch between the two by clicking on the Mini-Button or by choosing the appropriate menu command.</p>

<p>The window is divided into the input fields above, the output fields in the middle and the settings-selection at the bottom.</p>
<p>The input and output fields are arranged as a table whereas the columns depict the different number bases. The rows depict the different byte sizes: 8, 16, 32, 64 and n bytes. With n bytes, the number automatically uses as many bytes as are required to store the input value as an unsigned number.</p>

<p>When entering values, only specific digits are allowed. All non-allowed digits will be ignored (also the negativ sign, see further below).</p>
<ul>
<li><b>Dec</b>: Decimal number. The natural numbers we humans compute with. Digits: 0123456789</li>
<li><b>Hex</b>: Hexadecimal number. numbers with base 16, often seen in computer programs. Digits: 0123456789abcdef as well as ABCDEF</li>
<li><b>Bin</b>: Binary numbers. Every digit has just two values: 0 and 1. Additionally, you can enter the digits oO, iI and L.</li>
<li><b>Asc</b>: ASCII-Characters. The numbers are interpreted as a series of 8-Bit-Characters and are displayed as 7-Bit-ASCII with a leading 0. Any ASCII character can be used. Numbers which do not correspond to a valid 7-Bit-ASCII-Character will be displayed as a question mark ?.</li>
</ul>

<p>In the expanded window, there are a few settings which can be made and which can also be found in the application menu:</p>
<ul>
<li><b>Little ↔︎ Big</b>: Exchange of the input bytes to convert between Little- and Big-Endianness. Carful: Only use this if you know what you are doing.</li>
<li><b>Unsigned</b>: The input is expected to be unsigned and will be converted directly to all output fields.</li>
<li><b>1's complement</b>: The input is expected to be unsigned, gets converted with the 1's complement and will be displayed in the output fields.</li>
<li><b>2's complement</b>: The input is expected to be unsigned, gets converted with the 2's complement and will be displayed in the output fields.</li>
<li><b>ASCII</b>: Displays a separate window with a simple ASCII-Table with additional information for each character.</li>
<li><b>Menu Preferences</b>: The display of the ASCII window at program startup can be suppressed.</li>
</ul>

</article>


<article>
<header>
<h2>User-Interface elements of the ASCII window</h2>
</header>
<p>The window is divided into the ASCII characters above and the display options below.</p>
<p>Hover with the mouse over the characters to see additional information displayed in the lower section of the window.</p>
<ul>
<li><b>Escape</b>: Escape-Codes. In programming languages with the C-Syntax, certain ASCII characters can only be accessed by using so called escape codes. Instead of the official ISO codes, these escape sequences are displayed.</li>
<li><b>Code</b>: ISO-Codes. The first 32 characters are displayed with the official ISO code.</li>
<li><b>Hex</b>: Hexadecimal numbering of the characters.</li>
<li><b>Dec</b>: Decimal numbering of the characters.</li>
</ul>

</article>



<article>
<header>
<h2>Preferences</h2>
</header>
<p>At application startup:</p>
<ul>
<li><b>Hide ASCII-Window</b>: The window with the ASCII-data will be hidden upon application start.</li>
<li><b>Set conversion to defaults</b>: The conversion will be set to unsigned without Endianness-conversion at application startup.</li>
</ul>

<p>Keep Windows in Foreground:</p>
<ul>
<li><b>Extended Version</b>: The extended conversion window will be kept in the foreground at all times.</li>
<li><b>Mini-Version</b>: The Mini-Version will be kept in the foreground at all times.</li>
</ul>
</article>



<article>
<header>
<h2>Why isn't my 2's complement negative?</h2>
</header>
<p>There is often confusion between what exactly the 2's complement is. Many people think, that in a computer, the 2's complement is the same as a negative number. This is not really the truth.</p>
<p>We humans compute with the decimal system and the digits 0 to 9. To mark a number as negative, we use an additional sign: The negative-Sign. A computer though has only two digits available and has no additional sign digit. Therefore, a computer somehow has to encode an integer number such that both positive as well as negative numbers can be stored. The method which is used nowadays is the storing of negative numbers by converting the absolute number of the value with the 2's complement.</p>
<p>The 2's complement therefore always depicts a conversion of an absolute value, stored as a binary sequence. How the sequence will in the end be interpreted, meaning if it actually has a sign or not, is impossible to say just by looking at the value. For the computation of the 2's complement, this is irrelevant, it just converts any binary sequence it gets.</p>

<p>The many possibilities of interpreting a binary value, to convert it, clip it or enlarge it or in general present it to a user are manyfold an confusing. If all the possibilities would have been implemented in the application, the user interface of Bit Fiddle would have become very complicated. The developer has decided to only display the most important possibilities. The application will therefore convert values always the same way with the following scheme:</p>

<p><b>The exact sequence of conversion</b></p>

<ul>
<li>First, the input (Dec, Hex, Bin oder Asc) is converted to an internal format, consisting of single bits. Here indeed, only the digits listed above will be captured, everything else will be ignored. A negative decimal number therefore will always be read as its absolute value. The number of bits in the internal format corresponds precisely to the number of bits required to store the unsigned value in a multiple of 8 bits.</li>
<li>Then, if the <q>Little ↔︎ Big</q>-Option is active, the bytes of the internal format will be switched.</li>
<li>Then, the conversion takes place, speaking <q>Unsigned</q> (Which does nothing), <q>1's complement</q> or <q>2's complement</q>.</li>
<li>After that, ther RESULTING bits will be packaged into the output sizes.
  <ul>
    <li>If the internal format has more space than is required for the output, the higher-order bits will be clipped. For examle, the value 0b00110011 10101010 in the internal format will be come 0b10101010 when converting to an 8-Bit-Value. This corresponds to the usual integer-convertion-mechanism of may programming languages.</li>
    <li>If the internal format has less space than is required for the output, the value will be expanded ARITHMETICALLY. This means, that the internal value will be interpreded as a SIGNED value. For example, the value 0b10101010 in the internal format will be converted to 0b11111111 10101010 when converting to a 16-Bit-Value. This has been solved in this fashion because the non-arithmetic conversion (speaking filling up the value with zeros) is trivial and therefore can be omitted. It is expected that a user immediately sees that the conversion has been done arithmetically.</li>
  </ul>
</li>
<li>Then, the output sizes will be converted to the different bases. Here, the values will be presented again to the user as decimal, hexadecimal, binary and ASCII values.
  <ul>
    <li>Decimal numbers will be displayed in groups of 3 with the digits 0 to 9 with a space in between. In case the conversion was done with the 1's complement, no output will be generated for the decimal numbers. In case (and really just in case) of converting with the 2's complement, the output will be interpreted and displayed as a signed decimal value.</li>
    <li>Hexadecimal numbers will be dispalyed in pairs of hexadecimal digits with a space in between. The letter-digits will be displayed lower-case.</li>
    <li>Binary numbers will be displayed in groups of 8 with the binary digits 0 and 1 and with a space in between.</li>
    <li>ASCII-Strings will be displayed as sequences of 7-Bit-ASCII-Characters, whereas the eight bit will be set to 0. Single bytes which do not correspond to a valid ASCII-Character will be displayed as question marks ?.</li>
  </ul>
</li>
</ul>

<p>This conversion covers all non-trivial conversions of integer numbers.</p>

<p>As the input is always expected as unsigned, it is for example not possible to enter a signed hexadecimal value and expect it to be converted to a signed decimal value. For those being interested in such a conversion and interpretation, you can simply convert the number with the 2's complement and add a minus sign in front of the decimal number.</p>
</article>



</body></html>
